import pandas as pd
from pathlib import Path
import sys

"""
DEEP DASHBOARD VERIFICATION
============================
Verify every single metric shown in the dashboard against raw CSV data.
No assumptions - calculate everything from scratch.
"""

# Save output to file
output_file = Path("C:/Users/GEO/Desktop/Dashboard/dashboard_deep_verification.txt")
sys.stdout = open(output_file, 'w', encoding='utf-8')

print("=" * 80)
print("DEEP DASHBOARD VERIFICATION - Raw CSV vs Dashboard Display")
print("=" * 80)

# Load the merged CSV
csv_path = Path("C:/Users/GEO/Desktop/Dashboard/data/raw/chocoberry_cardiff/sales_data.csv")
df = pd.read_csv(csv_path)

print(f"\nðŸ“‚ Loaded: {csv_path.name}")
print(f"Total rows: {len(df):,}")

# Convert date column
df['Order time'] = pd.to_datetime(df['Order time'], errors='coerce')

# Filter to dashboard date range (Jan 4 - Feb 6, 2026)
df_filtered = df[(df['Order time'] >= '2026-01-04') & (df['Order time'] <= '2026-02-06')]

print(f"\nðŸ“… Date Range Filter:")
print(f"Start: 2026-01-04")
print(f"End: 2026-02-06")
print(f"Filtered rows: {len(df_filtered):,}")

# Dashboard shows: Jan 04, 2026 - Feb 06, 2026
min_date = df_filtered['Order time'].min()
max_date = df_filtered['Order time'].max()

print(f"\nActual data range:")
print(f"Min date: {min_date.date() if pd.notna(min_date) else 'N/A'}")
print(f"Max date: {max_date.date() if pd.notna(max_date) else 'N/A'}")

print("\n" + "=" * 80)
print("METRIC VERIFICATION - Dashboard vs Raw Data")
print("=" * 80)

# METRIC 1: Total Orders
print("\nðŸ“Š METRIC 1: TOTAL ORDERS")
print("-" * 80)

dashboard_total_orders = 5275  # From screenshot
actual_total_orders = len(df_filtered)

print(f"Dashboard shows:  {dashboard_total_orders:,}")
print(f"Raw CSV count:    {actual_total_orders:,}")
print(f"Difference:       {actual_total_orders - dashboard_total_orders:,}")

if dashboard_total_orders == actual_total_orders:
    print("âœ… MATCH - Total Orders is CORRECT")
else:
    print("âŒ ERROR - Total Orders doesn't match!")

# METRIC 2: Total Revenue
print("\nðŸ’° METRIC 2: TOTAL REVENUE")
print("-" * 80)

# Dashboard shows Â£81.0K
dashboard_revenue_display = "Â£81.0K"
dashboard_revenue_value = 81000  # Approximate from K notation

# Calculate from CSV - use 'Gross sales' column
df_filtered['Gross sales'] = pd.to_numeric(df_filtered['Gross sales'], errors='coerce')
actual_revenue = df_filtered['Gross sales'].sum()

print(f"Dashboard shows:  {dashboard_revenue_display}")
print(f"Raw CSV sum:      Â£{actual_revenue:,.2f}")
print(f"In K notation:    Â£{actual_revenue/1000:.1f}K")
print(f"Difference:       Â£{actual_revenue - dashboard_revenue_value:,.2f}")

revenue_diff_percent = abs(actual_revenue - dashboard_revenue_value) / actual_revenue * 100
if revenue_diff_percent < 1:  # Within 1% (K rounding tolerance)
    print(f"âœ… MATCH - Revenue is CORRECT (within {revenue_diff_percent:.2f}% - K rounding)")
else:
    print(f"âš ï¸  Check needed - Difference is {revenue_diff_percent:.2f}%")

# METRIC 3: Average Order
print("\nðŸ“ˆ METRIC 3: AVERAGE ORDER")
print("-" * 80)

dashboard_avg_order = 14.75  # From screenshot
actual_avg_order = actual_revenue / actual_total_orders

print(f"Dashboard shows:  Â£{dashboard_avg_order:.2f}")
print(f"Raw CSV calc:     Â£{actual_avg_order:.2f}")
print(f"  (Â£{actual_revenue:,.2f} Ã· {actual_total_orders:,})")
print(f"Difference:       Â£{abs(actual_avg_order - dashboard_avg_order):.2f}")

if abs(actual_avg_order - dashboard_avg_order) < 0.01:
    print("âœ… MATCH - Average Order is CORRECT")
else:
    print("âš ï¸  Small difference (may be rounding)")

# METRIC 4: Total Tax
print("\nðŸ§¾ METRIC 4: TOTAL TAX")
print("-" * 80)

dashboard_tax_display = "Â£3.0K"
dashboard_tax_value = 3000

# Calculate from CSV - use 'Tax on gross sales' column
df_filtered['Tax on gross sales'] = pd.to_numeric(df_filtered['Tax on gross sales'], errors='coerce')
actual_tax = df_filtered['Tax on gross sales'].sum()

print(f"Dashboard shows:  {dashboard_tax_display}")
print(f"Raw CSV sum:      Â£{actual_tax:,.2f}")
print(f"In K notation:    Â£{actual_tax/1000:.1f}K")
print(f"Difference:       Â£{actual_tax - dashboard_tax_value:,.2f}")

tax_diff_percent = abs(actual_tax - dashboard_tax_value) / actual_tax * 100
if tax_diff_percent < 1:
    print(f"âœ… MATCH - Total Tax is CORRECT (within {tax_diff_percent:.2f}% - K rounding)")
else:
    print(f"âš ï¸  Check needed - Difference is {tax_diff_percent:.2f}%")

# METRIC 5: Delivery Charges
print("\nðŸšš METRIC 5: DELIVERY CHARGES")
print("-" * 80)

dashboard_delivery = 159.84  # From screenshot

# Calculate from CSV - use 'Delivery charges' column
df_filtered['Delivery charges'] = pd.to_numeric(df_filtered['Delivery charges'], errors='coerce')
actual_delivery = df_filtered['Delivery charges'].sum()

print(f"Dashboard shows:  Â£{dashboard_delivery:.2f}")
print(f"Raw CSV sum:      Â£{actual_delivery:.2f}")
print(f"Difference:       Â£{abs(actual_delivery - dashboard_delivery):.2f}")

if abs(actual_delivery - dashboard_delivery) < 0.01:
    print("âœ… MATCH - Delivery Charges is CORRECT")
else:
    print("âš ï¸  Difference detected")

# ADDITIONAL VERIFICATION: Sample random orders
print("\n" + "=" * 80)
print("SAMPLE ORDER VERIFICATION")
print("=" * 80)

print("\nChecking 5 random orders for data integrity...")
sample = df_filtered.sample(min(5, len(df_filtered)))

for idx, row in sample.iterrows():
    print(f"\nOrder: {row['Order ID']}")
    print(f"  Date: {row['Order time']}")
    print(f"  Gross Sales: Â£{row['Gross sales']:.2f}")
    print(f"  Tax: Â£{row['Tax on gross sales']:.2f}")
    print(f"  Valid: âœ“")

# FINAL SUMMARY
print("\n" + "=" * 80)
print("VERIFICATION SUMMARY")
print("=" * 80)

tests = []
tests.append(("Total Orders", dashboard_total_orders == actual_total_orders))
tests.append(("Total Revenue", revenue_diff_percent < 1))
tests.append(("Average Order", abs(actual_avg_order - dashboard_avg_order) < 0.01))
tests.append(("Total Tax", tax_diff_percent < 1))
tests.append(("Delivery Charges", abs(actual_delivery - dashboard_delivery) < 0.01))

passed = sum(1 for _, result in tests if result)
total = len(tests)

print("\nMetric Accuracy:")
for metric_name, result in tests:
    status = "âœ… CORRECT" if result else "âŒ MISMATCH"
    print(f"  {status}: {metric_name}")

print(f"\n{'='*80}")
print(f"ACCURACY: {passed}/{total} metrics verified")
print(f"{'='*80}")

# Detailed calculations for reference
print("\n" + "=" * 80)
print("DETAILED CALCULATIONS (for your records)")
print("=" * 80)

print(f"\nTotal Revenue Calculation:")
print(f"  Sum of 'Gross sales' column")
print(f"  = Â£{actual_revenue:,.2f}")
print(f"  = Â£{actual_revenue/1000:.1f}K (dashboard format)")

print(f"\nAverage Order Calculation:")
print(f"  Total Revenue Ã· Total Orders")
print(f"  = Â£{actual_revenue:,.2f} Ã· {actual_total_orders:,}")
print(f"  = Â£{actual_avg_order:.2f}")

print(f"\nTotal Tax Calculation:")
print(f"  Sum of 'Tax on gross sales' column")
print(f"  = Â£{actual_tax:,.2f}")
print(f"  = Â£{actual_tax/1000:.1f}K (dashboard format)")

print(f"\nDelivery Charges Calculation:")
print(f"  Sum of 'Delivery charges' column")
print(f"  = Â£{actual_delivery:,.2f}")

if passed == total:
    print("\n" + "=" * 80)
    print("âœ…âœ…âœ… ALL METRICS ARE CORRECT - NO HALLUCINATION âœ…âœ…âœ…")
    print("=" * 80)
    print("\nEvery value shown in the dashboard matches the raw CSV data.")
    print("No invented numbers, no incorrect calculations.")
else:
    print("\n" + "=" * 80)
    print(f"âš ï¸  {total - passed} METRIC(S) NEED ATTENTION")
    print("=" * 80)

sys.stdout.close()
sys.stdout = sys.__stdout__
print("âœ… Deep verification complete! Report saved to: dashboard_deep_verification.txt")
